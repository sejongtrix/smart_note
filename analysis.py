import os
import json
import whisper
import torch
from pdf2image import convert_from_path
from PIL import Image
import PyPDF2
import pandas as pd
import requests
import fitz
# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# Whisper ëª¨ë¸ì„ ì „ì—­ ë³€ìˆ˜ë¡œ ì„ ì–¸ (ì§€ì—° ë¡œë“œ)
whisper_model = None

def load_whisper_model():
    """Whisper ëª¨ë¸ì„ ì§€ì—° ë¡œë“œí•©ë‹ˆë‹¤."""
    global whisper_model
    if whisper_model is None:
        print("Whisper medium ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...")
        whisper_model = whisper.load_model("tiny", device=DEVICE)
        print("Whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
    return whisper_model

PROCESSED_FOLDER = 'processed'
if not os.path.exists(PROCESSED_FOLDER):
    os.makedirs(PROCESSED_FOLDER)

def transcribe_video(video_path, filename):
    """ìœ„ìŠ¤í¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ íŒŒì¼ì˜ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        print(f"{video_path}ì˜ ìŒì„± ì¸ì‹ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        model = load_whisper_model()
        
        # ë” ì•ˆì •ì ì¸ ì„¤ì •ìœ¼ë¡œ ìŒì„± ì¸ì‹ ìˆ˜í–‰
        result = model.transcribe(
            video_path, 
            verbose=True, 
            fp16=False,  # fp16ì„ ë¹„í™œì„±í™”í•˜ì—¬ ì•ˆì •ì„± í–¥ìƒ
            task='transcribe',  # ë²ˆì—­ì´ ì•„ë‹Œ ì „ì‚¬ ì‘ì—…
            temperature=0.2,  # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ temperatureë¥¼ 0ìœ¼ë¡œ ì„¤ì •
            #no_speech_threshold=0.6,  # ìŒì„±ì´ ì—†ëŠ” êµ¬ê°„ ê°ì§€ ì„ê³„ê°’
            #logprob_threshold=-1.0,  # ë¡œê·¸ í™•ë¥  ì„ê³„ê°’
            #compression_ratio_threshold=2.4  # ì••ì¶• ë¹„ìœ¨ ì„ê³„ê°’
        )
        
        # ê²°ê³¼ ë°ì´í„° ì •ë¦¬ ë° ê²€ì¦
        df = pd.read_csv("C:/Users/good1/Desktop/summer_vacation/smartnote/website/notes/slide_similarity_log.csv")
        page_segments = []
        prev_page = None
        for i, row in df.iterrows():
            if row['page'] != prev_page:
                page_segments.append({"time": row['seconds'], "page": int(row['page'])})
                prev_page = row['page']
        segments = []
        for segment in result.get('segments', []):
            segment_start = segment.get('start',0.0)
            current_page = 0
            for pseg in page_segments:
                if segment_start >= pseg['time']:
                    current_page = pseg['page']
                else:
                    break
            segments.append({
                'start': segment.get('start', 0.0),
                'end': segment.get('end', 0.0),
                'text': segment.get('text', '').strip(),
                'page': current_page
            })
        
        transcript_data = {
            'filename': filename,
            'transcript': result.get('text', '').strip(),
            'segments': segments,
            'language': result.get('language', 'unknown')
        }
        transcript_file = os.path.join(PROCESSED_FOLDER, f"{os.path.splitext(filename)[0]}_transcript.json")
        with open(transcript_file, 'w', encoding='utf-8') as f:
            json.dump(transcript_data, f, ensure_ascii=False, indent=2)
            
        print("ìŒì„± ì¸ì‹ ì™„ë£Œ ë° íŒŒì¼ ì €ì¥ ì„±ê³µ.")
        return transcript_data,segments

    except Exception as e:
        print(f'ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}')
        return {'error': str(e)}

def summarize_ai(raw_df,pdf_path):
    df = pd.DataFrame(raw_df)
    grouped = df.groupby('page', as_index=False).agg({
    'text': ' '.join  
    })

    example_df = grouped

    doc = fitz.open(pdf_path)

    # í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ì €ì¥
    data = []
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text = page.get_text()
        data.append({
            'page': page_num,
            'text': text.strip()
        })

    # DataFrameìœ¼ë¡œ ì €ì¥
    page_df = pd.DataFrame(data)


    # Ollama ì„œë²„ URL
    OLLAMA_URL = 'http://localhost:11434/api/generate'

    # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
    results = []

    for idx, row in example_df.iterrows():
        text1 = row['text'] 

        page_num = row['page']  # page ë²ˆí˜¸
        # page_dfì—ì„œ í•´ë‹¹í•˜ëŠ” pageì˜ text ê°€ì ¸ì˜¤ê¸°
        matched_rows = page_df[page_df['page'] == page_num]

        if matched_rows.empty:
            print(f"â— page {page_num}ì— í•´ë‹¹í•˜ëŠ” í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue

        text2 = matched_rows.iloc[0]['text']

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
        ë¬¸ì¥1ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì¥2ë¥¼ ë³´ì™„í•´ì¤˜. ë‹¨, ë¬¸ì¥1ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ê°€í•˜ì§€ ë§ê³  ë¬¸ì¥2 ì•ˆì˜ í‘œí˜„ì´ë‚˜ ë§¥ë½ì„ ë” êµ¬ì²´í™”í•˜ê±°ë‚˜ í’ë¶€í•˜ê²Œ í•´ì¤˜.

        ê²°ê³¼ëŠ” ë³´ì™„ëœ ë¬¸ì¥2ë§Œ ì¶œë ¥í•´. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë‚˜ ì„¤ëª…ì€ ìƒëµí•˜ê³ , ë„ˆì˜ ì‚¬ê³ ê³¼ì •ë„ ë“œëŸ¬ë‚´ì§€ ë§ˆ.

        ë¬¸ì¥1: {text1}
        ë¬¸ì¥2: {text2}
        """

        # ìš”ì²­ payload
        payload = {
            "model": "gemma3:12b",
            "prompt": prompt,
            "stream": False
        }

        # ìš”ì²­ ë³´ë‚´ê¸°
        response = requests.post(OLLAMA_URL, json=payload)
        # ì‘ë‹µ ì²˜ë¦¬
        if response.status_code == 200:
            result = response.json()
            print(f"(index {idx}):")
            print(result['response'])
            results.append({
                'index': idx,
                'page': page_num,
                'text1': text1,
                'text2': text2,
                'gemma_response': result['response']
            })
        else:
            print(f"âŒ ìš”ì²­ ì‹¤íŒ¨ (index {idx}): {response.status_code}")
            print(response.text)

    print("aiìš”ì•½ì™„ë£Œ")
    output_df = pd.DataFrame(results)
    output_df.to_csv('gemma_opinions.csv', index=False)
    output_df.to_json('gemma_opinions.json', orient='records', force_ascii=False, indent=2)
    return output_df

def process_pdf(pdf_path, filename,video_path):
    """PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    # ì—¬ê¸°ì„œ pdf ì²˜ë¦¬ ë¡œì§ ë‹¤ êµ¬í˜„ í•´ë²„ë¦¬ìê³  
    try:
        print(f"{pdf_path}ì˜ PDF ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        # 1. PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text_content = ""
        with open(pdf_path, 'rb') as f:
            reader = PyPDF2.PdfReader(f)
            for page in reader.pages:
                text_content += page.extract_text() + "\n\n"

        # 2. PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        images = convert_from_path(pdf_path)
        image_paths = []
        for i, image in enumerate(images):
            image_filename = f"{os.path.splitext(filename)[0]}_page_{i+1}.png"
            image_filepath = os.path.join(PROCESSED_FOLDER, image_filename)
            image.save(image_filepath, 'PNG')
            image_paths.append(image_filename)

        pdf_data = {
            'filename': filename,
            'text_content': text_content,
            'image_paths': image_paths,
            'total_pages': len(images)
        }

        pdf_file = os.path.join(PROCESSED_FOLDER, f"{os.path.splitext(filename)[0]}_processed.json")
        with open(pdf_file, 'w', encoding='utf-8') as f:
            json.dump(pdf_data, f, ensure_ascii=False, indent=2)

        print("PDF ì²˜ë¦¬ ë° íŒŒì¼ ì €ì¥ ì„±ê³µ.")
        # 3. pdfì™€ ë™ì˜ìƒ íŒŒì¼ë¡œ 
        matching_pdf_and_video(images, video_path)
        return pdf_data

    except Exception as e:
        print(f'PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}')
        return {'error': str(e)}
    
def matching_pdf_and_video(images, video_path):
    """PDF ë°ì´í„°ì™€ ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ë§¤ì¹­í•©ë‹ˆë‹¤."""
    import torch
    import torchvision.models as models
    import torchvision.transforms as transforms
    from PIL import Image
    from torch.nn.functional import cosine_similarity
    import io
    import cv2
    import numpy as np
    import csv

    print("ğŸ”§ ëª¨ë¸ ë¡œë”© ì¤‘...")
    model = models.resnet50(pretrained=True)
    model = torch.nn.Sequential(*list(model.children())[:-1]) 
    model.eval()
    print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")


    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                            std=[0.229, 0.224, 0.225])
    ])

    # ë¡œê·¸ íŒŒì¼ ì„¤ì •
    output_path = "slide_similarity_log.csv"
    csv_file = open(output_path, mode="w", newline="", encoding="utf-8")
    csv_writer = csv.writer(csv_file)
    csv_writer.writerow(["seconds", "page", "similarity"])
    print(f"ğŸ“ CSV ë¡œê·¸ íŒŒì¼ ì´ˆê¸°í™” ì™„ë£Œ: {output_path}")

    # MSE ìœ ì‚¬ë„ ì¸¡ì • í•¨ìˆ˜
    def mse(imageA, imageB):
        err = np.sum((imageA.astype("float") - imageB.astype("float")) ** 2)
        err /= float(imageA.shape[0] * imageA.shape[1])
        return err

    # í”„ë ˆì„ â†’ feature ì¶”ì¶œ
    def extract_feature(image):
        if isinstance(image, np.ndarray):
            image = Image.fromarray(image).convert("RGB")
        else:
            image = image.convert("RGB")
        tensor = transform(image).unsqueeze(0)
        with torch.no_grad():
            feature = model(tensor).squeeze()
        return feature

    # ì˜ìƒ íŒŒì¼ ë¡œë”©
    print("ğŸï¸ ì˜ìƒ ë¡œë”© ì¤‘...")
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    print(f"âœ… ì˜ìƒ ë¡œë”© ì™„ë£Œ - FPS: {fps:.2f}")
    frame_interval = int(fps * 1)
    def is_last_page(page_index,doc_length):
        return page_index == doc_length - 1
    # ìƒíƒœ ë³€ìˆ˜ë“¤
    last_slide = None
    last_best_page = 0
    prev_sim = None
    frame_count = 0

    # í•˜ì´í¼íŒŒë¼ë¯¸í„°
    mse_threshold = 500
    sim_drop_threshold = 0.01
    max_search_range = 20

    print("ğŸš€ ë¶„ì„ ì‹œì‘")

    # ë©”ì¸ ë£¨í”„
    while True:
        ret, frame = cap.read()
        if not ret:
            print("ğŸ¬ ì˜ìƒ ë")
            break

        frame_time = frame_count / fps

        if frame_count % frame_interval == 0:
            #print(f"\nğŸ§­ í”„ë ˆì„ {frame_count} (ì‹œê°„: {frame_time:.2f}ì´ˆ) ë¶„ì„ ì¤‘...")
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.resize(gray, (320, 240))

            if last_slide is None:
                print("ğŸ†• ì²« ìŠ¬ë¼ì´ë“œë¡œ ì„¤ì •")
                last_slide = gray
            else:
                diff = mse(gray, last_slide)
                #print(f"ğŸ” MSE ì°¨ì´: {diff:.2f}")

                if diff > mse_threshold:
                    print("ğŸ“ˆ ìŠ¬ë¼ì´ë“œ ë³€ê²½ ê°ì§€ë¨ â†’ íƒìƒ‰ ì‹œì‘")
                    frame_sim_results = []

                    for offset in range(-int(2 * fps), int(2 * fps) + 1, frame_interval):
                        pos = frame_count + offset
                        if pos < 0 or pos >= cap.get(cv2.CAP_PROP_FRAME_COUNT):
                            continue

                        cap.set(cv2.CAP_PROP_POS_FRAMES, pos)
                        ret2, temp_frame = cap.read()
                        if not ret2:
                            continue

                        frame_rgb = cv2.cvtColor(temp_frame, cv2.COLOR_BGR2RGB)
                        feat1 = extract_feature(frame_rgb)

                        # ê¸°ë³¸ í›„ë³´ í˜ì´ì§€ ì„¤ì •
                        candidate_range = [-2, -1, 0, 1, 2]
                        candidates = [last_best_page + i for i in candidate_range if 0 <= last_best_page + i < len(images)]

                        best_page = last_best_page
                        max_sim = -1

                        print(f"ğŸ” 1ì°¨ íƒìƒ‰: í›„ë³´ í˜ì´ì§€ {candidates}")
                        for i in candidates:
                            page = images[i]
                            #pix = page.get_pixmap(dpi=300)
                            #img_bytes = pix.tobytes("ppm")
                            feat2 = extract_feature(page)
                            sim = cosine_similarity(feat1.unsqueeze(0), feat2.unsqueeze(0)).item()

                            print(f"    í˜ì´ì§€ {i} ìœ ì‚¬ë„: {sim:.4f}")
                            if sim > max_sim:
                                max_sim = sim
                                best_page = i
                                best_feat2 = feat2

                        # ìœ ì‚¬ë„ ê¸‰ë½ ì‹œ ì¬íƒìƒ‰
                        if prev_sim is not None and (prev_sim - max_sim) >= sim_drop_threshold:
                            print(f"âš ï¸ ìœ ì‚¬ë„ í•˜ë½ ê°ì§€ (ì´ì „: {prev_sim:.4f} â†’ í˜„ì¬: {max_sim:.4f}) â†’ 2ì°¨ íƒìƒ‰")
                            expanded_range = list(range(-(max_search_range//2), max_search_range//2 + 1))
                            expanded_candidates = [last_best_page + i for i in expanded_range if 0 <= last_best_page + i < len(images)]

                            print(f"ğŸ” 2ì°¨ íƒìƒ‰: í›„ë³´ í˜ì´ì§€ {expanded_candidates}")
                            for i in expanded_candidates:
                                page = images[i]
                                #pix = page.get_pixmap(dpi=300)
                                #img_bytes = pix.tobytes("ppm")
                                feat2 = extract_feature(page)
                                sim = cosine_similarity(feat1.unsqueeze(0), feat2.unsqueeze(0)).item()

                                print(f"    [2ì°¨] í˜ì´ì§€ {i} ìœ ì‚¬ë„: {sim:.4f}")
                                if sim > max_sim:
                                    max_sim = sim
                                    best_page = i
                                    best_feat2 = feat2

                        result_time = pos / fps
                        minutes = int(result_time // 60)
                        seconds = int(result_time % 60)
                        print(f"âœ… [ê²°ê³¼] {minutes}ë¶„ {seconds}ì´ˆ: í˜ì´ì§€ {best_page} / ìœ ì‚¬ë„ {max_sim:.4f}")
                        csv_writer.writerow([round(result_time, 2), best_page, round(max_sim, 4)])
                        frame_sim_results.append((max_sim, best_page, result_time, gray))

                    if frame_sim_results:
                        best_result = max(frame_sim_results, key=lambda x: x[0])
                        prev_sim = best_result[0]
                        last_best_page = best_result[1]
                        last_slide = best_result[3]
                        print(f"ğŸ“Œ í˜„ì¬ ìƒíƒœ ê°±ì‹  â†’ í˜ì´ì§€ {last_best_page}, ìœ ì‚¬ë„ {prev_sim:.4f}")
                        
                        if is_last_page(last_best_page, len(images)):
                            print(f"ğŸš© ë§ˆì§€ë§‰ í˜ì´ì§€({last_best_page}) ë„ë‹¬, ì¢…ë£Œí•©ë‹ˆë‹¤.")
                            break

        frame_count += 1

    cap.release()
    csv_file.close()
    print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ. ë¡œê·¸ ì €ì¥ë¨.")
